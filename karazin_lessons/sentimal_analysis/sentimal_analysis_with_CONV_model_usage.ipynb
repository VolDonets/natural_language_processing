{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import dependencies",
   "id": "cbc544ca487e6505"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T08:30:19.402037Z",
     "start_time": "2024-11-08T08:30:14.155881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import gensim.downloader as gensim_api\n",
    "from nltk.tokenize import TreebankWordTokenizer"
   ],
   "id": "b7fd6c37d984554b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load word vectors",
   "id": "dc85d71038aaa14c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T08:31:01.212120Z",
     "start_time": "2024-11-08T08:30:19.403048Z"
    }
   },
   "cell_type": "code",
   "source": "word_vectors = gensim_api.load(\"word2vec-google-news-300\")  # 300-dimensional vectors",
   "id": "4557b0f01bb018e5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Process text",
   "id": "9b959155cb6b01b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T08:31:04.853159Z",
     "start_time": "2024-11-08T08:31:04.846959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_and_vectorize(dataset_):\n",
    "    tokenizer_ = TreebankWordTokenizer()\n",
    "    vectorized_data_ = []\n",
    "    expected_ = []\n",
    "    for sample_ in dataset_:\n",
    "        tokens_ = tokenizer_.tokenize(sample_[1])\n",
    "        sample_vecs_ = []\n",
    "        for token_ in tokens_:\n",
    "            try:\n",
    "                sample_vecs_.append(word_vectors[token_])\n",
    "            except KeyError:\n",
    "                pass\n",
    "        vectorized_data_.append(sample_vecs_)\n",
    "        expected_.append(sample_[0])\n",
    "    return vectorized_data_, expected_"
   ],
   "id": "2f2eba9819f5f097",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T08:31:05.059943Z",
     "start_time": "2024-11-08T08:31:05.054807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pad_trunc(data_, maxlen_):\n",
    "    new_data_ = []\n",
    "    zero_vector_ = [0.0 for _ in range(len(data_[0][0]))]\n",
    "    for sample_ in data_:\n",
    "        if len(sample_) > maxlen_:\n",
    "            temp_ = sample_[:maxlen_]\n",
    "        elif len(sample_) < maxlen_:\n",
    "            temp_ = sample_\n",
    "            additional_elems_ = maxlen_ - len(sample_)\n",
    "            for _ in range(additional_elems_):\n",
    "                temp_.append(zero_vector_)\n",
    "        else:\n",
    "            temp_ = sample_\n",
    "        new_data_.append(temp_)\n",
    "    return new_data_"
   ],
   "id": "d8f1b7ec398db63d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load the model",
   "id": "beb56669eb8b318d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T08:37:01.418152Z",
     "start_time": "2024-11-08T08:37:01.342748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"resulting_models/CONV_sentimal/cnn_model.json\", 'r') as json_file:\n",
    "    json_string = json_file.read()\n",
    "model = tf.keras.models.model_from_json(json_string)\n",
    "model.load_weights('resulting_models/CONV_sentimal/cnn_weights.weights.h5')"
   ],
   "id": "8d1a690ff1dce429",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Do experiment",
   "id": "71021c1414e56c97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T08:44:42.015794Z",
     "start_time": "2024-11-08T08:44:42.009288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "statement = {\n",
    "    0: \"NEGATIVE\",\n",
    "    1: \"POSITIVE\",\n",
    "}\n",
    "\n",
    "def is_positive(prediction_array):\n",
    "    return statement[0] if prediction_array[0][0] < 0.5 else statement[1]"
   ],
   "id": "53953ae7d8506b04",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T08:45:02.770928Z",
     "start_time": "2024-11-08T08:45:02.700025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_1 = \"I hate that the dismal weather had me down for so long, \" \\\n",
    "           \"when will it break! Ugh, when does happiness return? The sun is blinding \" \\\n",
    "           \"and the puffy clouds are too thin. I can't wait for the weekend.\"\n",
    "\n",
    "maxlen = 400\n",
    "embedding_dims = 300\n",
    "dataset = [[1, sample_1]]\n",
    "vec_list, expected = tokenize_and_vectorize(dataset)\n",
    "test_vec_list = pad_trunc(vec_list, maxlen)\n",
    "test_vec = np.reshape(test_vec_list, (len(test_vec_list), maxlen, embedding_dims))\n",
    "prediction = model.predict(test_vec)\n",
    "\n",
    "print('Prediction for negative sentence:', is_positive(prediction))"
   ],
   "id": "9222fb197271d529",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "Prediction for negative sentence: NEGATIVE\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T08:45:09.356904Z",
     "start_time": "2024-11-08T08:45:09.280028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_1 = \"\"\"Every day brings new opportunities to learn, grow, and make a difference. With a little effort and a positive mindset, even small steps can lead to incredible progress. Remember, each challenge we face is a chance to become stronger and more resilient. Celebrate the little wins along the way, and don't forget that you're capable of achieving amazing things. The future is bright, and each decision you make today builds towards a better tomorrow. Keep going—you've got this!\"\"\"\n",
    "\n",
    "maxlen = 400\n",
    "embedding_dims = 300\n",
    "dataset = [[1, sample_1]]\n",
    "vec_list, expected = tokenize_and_vectorize(dataset)\n",
    "test_vec_list = pad_trunc(vec_list, maxlen)\n",
    "test_vec = np.reshape(test_vec_list, (len(test_vec_list), maxlen, embedding_dims))\n",
    "prediction = model.predict(test_vec)\n",
    "\n",
    "print('Prediction for negative sentence:', is_positive(prediction))"
   ],
   "id": "72cd8604b26a6cea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "Prediction for negative sentence: POSITIVE\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T08:45:14.122279Z",
     "start_time": "2024-11-08T08:45:14.039824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_1 = \"\"\"Some days, no matter how much effort you put in, things just don’t seem to go right. Progress feels slow, and setbacks can feel overwhelming. It’s tough when challenges keep piling up and solutions seem out of reach. Frustrations build, and it can be hard to see a way forward. Even the small wins don’t seem to add up, leaving a sense that all efforts might be in vain.\"\"\"\n",
    "\n",
    "maxlen = 400\n",
    "embedding_dims = 300\n",
    "dataset = [[1, sample_1]]\n",
    "vec_list, expected = tokenize_and_vectorize(dataset)\n",
    "test_vec_list = pad_trunc(vec_list, maxlen)\n",
    "test_vec = np.reshape(test_vec_list, (len(test_vec_list), maxlen, embedding_dims))\n",
    "prediction = model.predict(test_vec)\n",
    "\n",
    "print('Prediction for negative sentence:', is_positive(prediction))"
   ],
   "id": "bf37b88390cc14c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "Prediction for negative sentence: NEGATIVE\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "171f93c16d2b78d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T08:46:05.728580Z",
     "start_time": "2024-11-08T08:46:05.725070Z"
    }
   },
   "cell_type": "code",
   "source": "# TODO pass more negative and positive samples",
   "id": "e390abae7b1c871b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7504590ee35d332f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
